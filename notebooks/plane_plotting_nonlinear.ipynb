{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import tabulate\n",
    "from sklearn.decomposition import PCA\n",
    "import os \n",
    "\n",
    "os.chdir('/home/tristan/loss-subspace-geometry-project/loss-subspace-geometry/src')\n",
    "\n",
    "\n",
    "from models.mlp import SubspaceNN, NN, NonLinearSubspaceNN\n",
    "from models.subspace_layers import LinesNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp.linear.weight\n",
      "mlp.linear.bias\n",
      "mlp.linear.line.parameterization_linear_1.weight\n",
      "mlp.linear.line.parameterization_linear_1.bias\n",
      "mlp.linear.line.parameterization_linear_2.weight\n",
      "mlp.linear.line.parameterization_linear_2.bias\n",
      "mlp.linear.line.parameterization_linear_3.weight\n",
      "mlp.linear.line.parameterization_linear_3.bias\n",
      "mlp.linear.line.parameterization_linear_4.weight\n",
      "mlp.linear.line.parameterization_linear_4.bias\n",
      "out.weight\n",
      "out.bias\n",
      "out.line.parameterization_linear_1.weight\n",
      "out.line.parameterization_linear_1.bias\n",
      "out.line.parameterization_linear_2.weight\n",
      "out.line.parameterization_linear_2.bias\n",
      "out.line.parameterization_linear_3.weight\n",
      "out.line.parameterization_linear_3.bias\n",
      "out.line.parameterization_linear_4.weight\n",
      "out.line.parameterization_linear_4.bias\n",
      "mlp.linear.weight\n",
      "mlp.linear.bias\n",
      "mlp.linear.line.parameterization_linear_1.weight\n",
      "mlp.linear.line.parameterization_linear_1.bias\n",
      "mlp.linear.line.parameterization_linear_2.weight\n",
      "mlp.linear.line.parameterization_linear_2.bias\n",
      "mlp.linear.line.parameterization_linear_3.weight\n",
      "mlp.linear.line.parameterization_linear_3.bias\n",
      "mlp.linear.line.parameterization_linear_4.weight\n",
      "mlp.linear.line.parameterization_linear_4.bias\n",
      "out.weight\n",
      "out.bias\n",
      "out.line.parameterization_linear_1.weight\n",
      "out.line.parameterization_linear_1.bias\n",
      "out.line.parameterization_linear_2.weight\n",
      "out.line.parameterization_linear_2.bias\n",
      "out.line.parameterization_linear_3.weight\n",
      "out.line.parameterization_linear_3.bias\n",
      "out.line.parameterization_linear_4.weight\n",
      "out.line.parameterization_linear_4.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configs\n",
    "data_dim = 784\n",
    "hidden_size = 512\n",
    "out_dim = 10\n",
    "dropout_prob = 0.3\n",
    "seed = 1256\n",
    "train_beta = 0.5\n",
    "vanilla_seed = 450\n",
    "# device = torch.device('cuda')\n",
    "device = torch.device('cuda:2')\n",
    "activation = 'tanh'\n",
    "\n",
    "model_path = f'/home/tristan/loss-subspace-geometry-project/loss-subspace-geometry-save/models/nonlinear_subspace_vanilla_mlp_seed_{seed}_beta_{train_beta}_{activation}_0.pt'\n",
    "\n",
    "curve_model = NonLinearSubspaceNN(input_dim=data_dim, \n",
    "                         hidden_dim=hidden_size, \n",
    "                         out_dim=out_dim, \n",
    "                         dropout_prob=dropout_prob, \n",
    "                         seed=seed).to(device)\n",
    "\n",
    "for tuple in curve_model.state_dict():\n",
    "    print(tuple)\n",
    "\n",
    "checkpoint = torch.load(model_path)\n",
    "for tuple in checkpoint:\n",
    "    print(tuple)\n",
    "curve_model.load_state_dict(checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more configs\n",
    "\n",
    "grid_points = 15\n",
    "margin_left = 0.2\n",
    "margin_right = 0.2\n",
    "margin_bottom = 0.2\n",
    "margin_top = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NonLinearSubspaceNN(\n",
       "  (mlp): NonLinearSubspaceMLP(\n",
       "    (linear): LinesNN(\n",
       "      in_features=784, out_features=512, bias=True\n",
       "      (line): ParameterizedSubspace(\n",
       "        (parameterization_linear_1): Linear(in_features=1, out_features=10, bias=True)\n",
       "        (parameterization_linear_2): Linear(in_features=10, out_features=20, bias=True)\n",
       "        (parameterization_linear_3): Linear(in_features=20, out_features=40, bias=True)\n",
       "        (parameterization_linear_4): Linear(in_features=40, out_features=401408, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (out): LinesNN(\n",
       "    in_features=512, out_features=10, bias=True\n",
       "    (line): ParameterizedSubspace(\n",
       "      (parameterization_linear_1): Linear(in_features=1, out_features=10, bias=True)\n",
       "      (parameterization_linear_2): Linear(in_features=10, out_features=20, bias=True)\n",
       "      (parameterization_linear_3): Linear(in_features=20, out_features=40, bias=True)\n",
       "      (parameterization_linear_4): Linear(in_features=40, out_features=5120, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activation == 'relu':\n",
    "    curve_parameters = list(curve_model.parameters())\n",
    "    for (i,(name, param)) in enumerate(curve_model.named_parameters()):\n",
    "        print(f\"{i}: {name}:\")\n",
    "    w = []\n",
    "\n",
    "    # actual neural net\n",
    "    w.append(np.concatenate([\n",
    "            # weights layer 1, biases layer 1, weights layer 2, biases layer 2\n",
    "            p.data.cpu().numpy().ravel() for p in [curve_parameters[0], curve_parameters[1], curve_parameters[6], curve_parameters[7]]\n",
    "        ]))\n",
    "\n",
    "    # subspace network 1 parameters\n",
    "    w.append(np.concatenate([\n",
    "            # weights layer 1, biases layer 1, weights layer 2, biases layer 2\n",
    "            p.data.cpu().numpy().ravel() for p in [curve_parameters[2], curve_parameters[3], curve_parameters[4], curve_parameters[5]]\n",
    "        ]))\n",
    "\n",
    "    # subspace network 2 parameters\n",
    "    w.append(np.concatenate([\n",
    "            # weights layer 1, biases layer 1, weights layer 2, biases layer 2\n",
    "            p.data.cpu().numpy().ravel() for p in [curve_parameters[8], curve_parameters[9], curve_parameters[10], curve_parameters[11]]\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: mlp.linear.weight:\n",
      "1: mlp.linear.bias:\n",
      "2: mlp.linear.line.parameterization_linear_1.weight:\n",
      "3: mlp.linear.line.parameterization_linear_1.bias:\n",
      "4: mlp.linear.line.parameterization_linear_2.weight:\n",
      "5: mlp.linear.line.parameterization_linear_2.bias:\n",
      "6: mlp.linear.line.parameterization_linear_3.weight:\n",
      "7: mlp.linear.line.parameterization_linear_3.bias:\n",
      "8: mlp.linear.line.parameterization_linear_4.weight:\n",
      "9: mlp.linear.line.parameterization_linear_4.bias:\n",
      "10: out.weight:\n",
      "11: out.bias:\n",
      "12: out.line.parameterization_linear_1.weight:\n",
      "13: out.line.parameterization_linear_1.bias:\n",
      "14: out.line.parameterization_linear_2.weight:\n",
      "15: out.line.parameterization_linear_2.bias:\n",
      "16: out.line.parameterization_linear_3.weight:\n",
      "17: out.line.parameterization_linear_3.bias:\n",
      "18: out.line.parameterization_linear_4.weight:\n",
      "19: out.line.parameterization_linear_4.bias:\n"
     ]
    }
   ],
   "source": [
    "if activation == 'tanh':\n",
    "    curve_parameters = list(curve_model.parameters())\n",
    "    for (i,(name, param)) in enumerate(curve_model.named_parameters()):\n",
    "        print(f\"{i}: {name}:\")\n",
    "    w = []\n",
    "\n",
    "    # actual neural net\n",
    "    w.append(np.concatenate([\n",
    "            # weights layer 1, biases layer 1, weights layer 2, biases layer 2\n",
    "            p.data.cpu().numpy().ravel() for p in [curve_parameters[0], curve_parameters[1], curve_parameters[10], curve_parameters[11]]\n",
    "        ]))\n",
    "\n",
    "    # subspace network 1 parameters\n",
    "    w.append(np.concatenate([\n",
    "            # weights layer 1, biases layer 1, weights layer 2, biases layer 2\n",
    "            p.data.cpu().numpy().ravel() for p in curve_parameters[2:10]\n",
    "        ]))\n",
    "\n",
    "    # subspace network 2 parameters\n",
    "    w.append(np.concatenate([\n",
    "            # weights layer 1, biases layer 1, weights layer 2, biases layer 2\n",
    "            p.data.cpu().numpy().ravel() for p in curve_parameters[12:20]\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isolated_model = NN(input_dim=data_dim, \n",
    "                         hidden_dim=hidden_size, \n",
    "                         out_dim=out_dim, \n",
    "                         dropout_prob=dropout_prob).to(device)\n",
    "isolated_checkpoint = torch.load(f'/home/tristan/loss-subspace-geometry-project/loss-subspace-geometry-save/models/vanilla_mlp_seed_{vanilla_seed}_0.pt')\n",
    "isolated_model.load_state_dict(isolated_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (mlp): MLP(\n",
       "    (linear): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (out): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isolated_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_weights = np.concatenate([\n",
    "        p.data.cpu().numpy().ravel() for p in list(isolated_model.parameters())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_subspace_relu(alpha, subspace_net_1, subspace_net_2):\n",
    "    alpha = torch.tensor([float(alpha)])\n",
    "    setattr(subspace_net_1, 'alpha', alpha)\n",
    "    setattr(subspace_net_2, 'alpha', alpha)\n",
    "    w1 = subspace_net_1.get_weight().clone().detach()\n",
    "    b1 = curve_parameters[1].clone().detach().cpu()\n",
    "    w2 = subspace_net_2.get_weight().clone().detach()\n",
    "    b2 = curve_parameters[7].clone().detach().cpu()\n",
    "    weights = torch.cat([w1,b1,w2,b2]).numpy()\n",
    "    return weights\n",
    "\n",
    "def sample_subspace_tanh(alpha, subspace_net_1, subspace_net_2):\n",
    "    alpha = torch.tensor([float(alpha)])\n",
    "    setattr(subspace_net_1, 'alpha', alpha)\n",
    "    setattr(subspace_net_2, 'alpha', alpha)\n",
    "    w1 = subspace_net_1.get_weight().clone().detach()\n",
    "    b1 = curve_parameters[1].clone().detach().cpu()\n",
    "    w2 = subspace_net_2.get_weight().clone().detach()\n",
    "    b2 = curve_parameters[11].clone().detach().cpu()\n",
    "    weights = torch.cat([w1,b1,w2,b2]).numpy()\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/envs/loss-subspace/lib/python3.8/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "## Sample uniformly from subspace ##\n",
    "samples = 1000\n",
    "alphas = np.linspace(0, 1, samples)\n",
    "\n",
    "# instantiate both subspace networks\n",
    "subspace_net_1 = LinesNN(\n",
    "    in_features=data_dim,\n",
    "    out_features=hidden_size\n",
    ")\n",
    "\n",
    "subspace_net_2 = LinesNN(\n",
    "    in_features=hidden_size,\n",
    "    out_features=out_dim\n",
    ")\n",
    "\n",
    "if activation == \"tanh\":\n",
    "    # set subspace network weights\n",
    "    sample_subspace = sample_subspace_tanh\n",
    "    with torch.no_grad():\n",
    "        subspace_net_1.line.parameterization_linear_1.weight.copy_(curve_parameters[2])\n",
    "        subspace_net_1.line.parameterization_linear_1.bias.copy_(curve_parameters[3])\n",
    "        subspace_net_1.line.parameterization_linear_2.weight.copy_(curve_parameters[4])\n",
    "        subspace_net_1.line.parameterization_linear_2.bias.copy_(curve_parameters[5])\n",
    "        subspace_net_1.line.parameterization_linear_3.weight.copy_(curve_parameters[6])\n",
    "        subspace_net_1.line.parameterization_linear_3.bias.copy_(curve_parameters[7])\n",
    "        subspace_net_1.line.parameterization_linear_4.weight.copy_(curve_parameters[8])\n",
    "        subspace_net_1.line.parameterization_linear_4.bias.copy_(curve_parameters[9])\n",
    "\n",
    "        subspace_net_2.line.parameterization_linear_1.weight.copy_(curve_parameters[12])\n",
    "        subspace_net_2.line.parameterization_linear_1.bias.copy_(curve_parameters[13])\n",
    "        subspace_net_2.line.parameterization_linear_2.weight.copy_(curve_parameters[14])\n",
    "        subspace_net_2.line.parameterization_linear_2.bias.copy_(curve_parameters[15])\n",
    "        subspace_net_2.line.parameterization_linear_3.weight.copy_(curve_parameters[16])\n",
    "        subspace_net_2.line.parameterization_linear_3.bias.copy_(curve_parameters[17])\n",
    "        subspace_net_2.line.parameterization_linear_4.weight.copy_(curve_parameters[18])\n",
    "        subspace_net_2.line.parameterization_linear_4.bias.copy_(curve_parameters[19])\n",
    "\n",
    "if activation == \"relu\":\n",
    "    sample_subspace = sample_subspace_relu\n",
    "    # set subspace network weights\n",
    "    with torch.no_grad():\n",
    "        subspace_net_1.line.parameterization_linear_1.weight.copy_(curve_parameters[2])\n",
    "        subspace_net_1.line.parameterization_linear_1.bias.copy_(curve_parameters[3])\n",
    "        subspace_net_1.line.parameterization_linear_2.weight.copy_(curve_parameters[4])\n",
    "        subspace_net_1.line.parameterization_linear_2.bias.copy_(curve_parameters[5])\n",
    "\n",
    "        subspace_net_2.line.parameterization_linear_1.weight.copy_(curve_parameters[8])\n",
    "        subspace_net_2.line.parameterization_linear_1.bias.copy_(curve_parameters[9])\n",
    "        subspace_net_2.line.parameterization_linear_2.weight.copy_(curve_parameters[10])\n",
    "        subspace_net_2.line.parameterization_linear_2.bias.copy_(curve_parameters[11])\n",
    "\n",
    "# sample points in weight space\n",
    "weight_space_points = []\n",
    "for alpha in alphas:\n",
    "    weights = sample_subspace(alpha, subspace_net_1, subspace_net_2)\n",
    "    weight_space_points.append(weights)\n",
    "\n",
    "weight_space_points = np.array(weight_space_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weight space samples\n",
    "np.savez(f'subspace_samples_seed_{seed}_beta_{train_beta}_{activation}.npz', weight_space_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on sampled weight space points to get top two principle eigenvectors\n",
    "weight_space_points = np.asarray(weight_space_points)\n",
    "pca = PCA().fit(weight_space_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/envs/loss-subspace/lib/python3.8/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "# calculate corners of hyperplane via projection onto principal vecs\n",
    "origin = sample_subspace(0.0, subspace_net_1, subspace_net_2)\n",
    "c3 = sample_subspace(1.0, subspace_net_1, subspace_net_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight space dimensionality: 407050\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set up for grid for plane plotting\n",
    "\n",
    "def get_xy(point, origin, vector_x, vector_y):\n",
    "    return np.array([np.dot(point - origin, vector_x), np.dot(point - origin, vector_y)])\n",
    "\n",
    "\n",
    "print('Weight space dimensionality: %d' % w[0].shape[0])\n",
    "\n",
    "u = c3-origin\n",
    "dx = np.linalg.norm(u)\n",
    "u /= dx\n",
    "\n",
    "v = np.random.uniform(size=u.shape)\n",
    "dy = np.linalg.norm(v)\n",
    "v /= dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_corners = [origin, c3, v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/envs/loss-subspace/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "bend_coordinates = np.stack(get_xy(p, origin, u, v) for p in w_corners)\n",
    "curve_coordinates = np.stack(get_xy(p, origin, u, v) for p in weight_space_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model: nn.Module, t):\n",
    "    weights = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear) and 'parameterization' not in name:\n",
    "            # add attribute for weight dimensionality and subspace dimensionality\n",
    "            setattr(module, f'alpha', torch.tensor([t], dtype=torch.float32, device=device))\n",
    "            print(module.get_weight())\n",
    "            weights.extend([module.get_weight(), module.bias.data])\n",
    "        # weights.extend([w for w in module.compute_weights_t(coeffs_t) if w is not None])\n",
    "    return np.concatenate([w.detach().cpu().numpy().ravel() for w in weights])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = grid_points\n",
    "alphas = np.linspace(0.0 - margin_left, 1.0 + margin_right, G)\n",
    "betas = np.linspace(0.0 - margin_bottom, 1.0 + margin_top, G)\n",
    "\n",
    "tr_loss = np.zeros((G, G))\n",
    "tr_nll = np.zeros((G, G))\n",
    "tr_acc = np.zeros((G, G))\n",
    "tr_err = np.zeros((G, G))\n",
    "\n",
    "te_loss = np.zeros((G, G))\n",
    "te_nll = np.zeros((G, G))\n",
    "te_acc = np.zeros((G, G))\n",
    "te_err = np.zeros((G, G))\n",
    "\n",
    "grid = np.zeros((G, G, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even more configs for evaluating on FashionMNIST\n",
    "data_dir = '/home/tristan/loss-subspace-geometry-project/data/'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "FashionMNIST_data_train = torchvision.datasets.FashionMNIST(\n",
    "    data_dir, train=True, transform=transform, download=False)\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(\n",
    "    FashionMNIST_data_train, [50000, 10000])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    val_set, batch_size=len(val_set), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model: nn.Module, loader):\n",
    "    running_loss = 0.0\n",
    "    num_right = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "            reshaped_x = x.reshape(x.size(0), 784)\n",
    "            y_hat = model(reshaped_x.to(device))\n",
    "            num_right += torch.sum(\n",
    "                y.to(device) == torch.argmax(\n",
    "                    y_hat, dim=-1)).detach().cpu().item()\n",
    "\n",
    "            running_loss += criterion(y_hat, y.to(device)).item()\n",
    "    return {\n",
    "        'nll': running_loss / len(loader.dataset),\n",
    "        'loss': running_loss / len(loader.dataset),\n",
    "        'accuracy': num_right * 100.0 / len(loader.dataset),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00]\n",
      " [ 2.00147241e-01 -1.17203344e-03]\n",
      " [ 4.00422335e-01 -2.34537752e-03]\n",
      " ...\n",
      " [ 2.23019348e+02 -1.34763771e+00]\n",
      " [ 2.23254654e+02 -1.34907504e+00]\n",
      " [ 2.23489960e+02 -1.35051280e+00]]\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      " -223.4900   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      " -223.4900   -184.2327        2.3874       2.3874            90.0100      2.3871           89.9500\n",
      " -223.4900     -0.0000        0.2083       0.2083             7.8080      0.2113            7.9800\n",
      " -223.4900    184.2327     1336.0825    1336.0825            90.0360   1324.3607           89.8200\n",
      " -223.4900    368.4654     3673.9278    3673.9278            90.0360   3647.1656           89.8200\n",
      " -223.4900    552.6982     6632.5813    6632.5813            90.0360   6588.7788           89.8200\n",
      " -223.4900    736.9309    10212.0451   10212.0451            90.0360  10149.2088           89.8200\n",
      " -223.4900    921.1636    14412.3172   14412.3172            90.0360  14328.4448           89.8200\n",
      " -223.4900   1105.3963    19233.3978   19233.3978            90.0360  19126.4960           89.8200\n",
      " -223.4900   1289.6290    24675.2915   24675.2915            90.0360  24543.3552           89.8200\n",
      " -223.4900   1473.8617    30737.9963   30737.9963            90.0360  30579.0272           89.8200\n",
      " -223.4900   1658.0945    37421.4932   37421.4932            90.0360  37233.4944           89.8200\n",
      " -223.4900   1842.3272    44725.8019   44725.8019            90.0360  44506.7808           89.8200\n",
      " -223.4900   2026.5599    52650.9161   52650.9161            90.0360  52398.8800           89.8200\n",
      " -223.4900   2210.7926    61196.8646   61196.8646            90.0360  60909.8048           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      " -111.7450   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      " -111.7450   -184.2327        2.3874       2.3874            90.0100      2.3871           89.9500\n",
      " -111.7450     -0.0000        0.2035       0.2035             7.6060      0.2077            7.7100\n",
      " -111.7450    184.2327     1310.9609    1310.9609            90.0360   1299.3677           89.8200\n",
      " -111.7450    368.4654     3636.4105    3636.4105            90.0360   3609.8664           89.8200\n",
      " -111.7450    552.6982     6582.6689    6582.6689            90.0360   6539.1760           89.8200\n",
      " -111.7450    736.9309    10149.7368   10149.7368            90.0360  10087.2976           89.8200\n",
      " -111.7450    921.1636    14337.6134   14337.6134            90.0360  14254.2288           89.8200\n",
      " -111.7450   1105.3963    19146.2984   19146.2984            90.0360  19039.9696           89.8200\n",
      " -111.7450   1289.6290    24575.7961   24575.7961            90.0360  24444.5280           89.8200\n",
      " -111.7450   1473.8617    30626.1054   30626.1054            90.0360  30467.9008           89.8200\n",
      " -111.7450   1658.0945    37297.2074   37297.2074            90.0360  37110.0704           89.8200\n",
      " -111.7450   1842.3272    44589.1209   44589.1209            90.0360  44371.0464           89.8200\n",
      " -111.7450   2026.5599    52501.8370   52501.8370            90.0360  52250.8160           89.8200\n",
      " -111.7450   2210.7926    61035.3948   61035.3948            90.0360  60749.4592           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "   -0.0000   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      "   -0.0000   -184.2327        2.3874       2.3874            90.0100      2.3871           89.9500\n",
      "   -0.0000     -0.0000        0.2008       0.2008             7.4860      0.2059            7.5400\n",
      "   -0.0000    184.2327     1286.0331    1286.0331            90.0360   1274.5674           89.8200\n",
      "   -0.0000    368.4654     3599.0872    3599.0872            90.0360   3572.7600           89.8200\n",
      "   -0.0000    552.6982     6532.9499    6532.9499            90.0360   6489.7640           89.8200\n",
      "   -0.0000    736.9309    10087.6226   10087.6226            90.0360  10025.5816           89.8200\n",
      "   -0.0000    921.1636    14263.1038   14263.1038            90.0360  14180.2064           89.8200\n",
      "   -0.0000   1105.3963    19059.3936   19059.3936            90.0360  18953.6448           89.8200\n",
      "   -0.0000   1289.6290    24476.4962   24476.4962            90.0360  24345.8944           89.8200\n",
      "   -0.0000   1473.8617    30514.4092   30514.4092            90.0360  30356.9568           89.8200\n",
      "   -0.0000   1658.0945    37173.1148   37173.1148            90.0360  36986.8128           89.8200\n",
      "   -0.0000   1842.3272    44452.6335   44452.6335            90.0360  44235.4912           89.8200\n",
      "   -0.0000   2026.5599    52352.9537   52352.9537            90.0360  52102.9664           89.8200\n",
      "   -0.0000   2210.7926    60874.1131   60874.1131            90.0360  60589.2928           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "  111.7450   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      "  111.7450   -184.2327        2.3874       2.3874            90.0100      2.3871           89.9500\n",
      "  111.7450     -0.0000        0.1994       0.1994             7.4360      0.2051            7.5600\n",
      "  111.7450    184.2327     1261.2993    1261.2993            90.0360   1249.9600           89.8200\n",
      "  111.7450    368.4654     3561.9577    3561.9577            90.0360   3535.8476           89.8200\n",
      "  111.7450    552.6982     6483.4249    6483.4249            90.0360   6440.5456           89.8200\n",
      "  111.7450    736.9309    10025.7022   10025.7022            90.0360   9964.0560           89.8200\n",
      "  111.7450    921.1636    14188.7878   14188.7878            90.0360  14106.3760           89.8200\n",
      "  111.7450   1105.3963    18972.6821   18972.6821            90.0360  18867.5040           89.8200\n",
      "  111.7450   1289.6290    24377.3892   24377.3892            90.0360  24247.4528           89.8200\n",
      "  111.7450   1473.8617    30402.9069   30402.9069            90.0360  30246.2144           89.8200\n",
      "  111.7450   1658.0945    37049.2188   37049.2188            90.0360  36863.7696           89.8200\n",
      "  111.7450   1842.3272    44316.3407   44316.3407            90.0360  44100.1408           89.8200\n",
      "  111.7450   2026.5599    52204.2666   52204.2666            90.0360  51955.3056           89.8200\n",
      "  111.7450   2210.7926    60713.0317   60713.0317            90.0360  60429.3376           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "  223.4900   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      "  223.4900   -184.2327        2.3874       2.3874            90.0100      2.3871           89.9500\n",
      "  223.4900     -0.0000        0.1989       0.1989             7.4160      0.2051            7.5400\n",
      "  223.4900    184.2327     1236.7592    1236.7592            90.0360   1225.5455           89.8200\n",
      "  223.4900    368.4654     3525.0221    3525.0221            90.0360   3499.1272           89.8200\n",
      "  223.4900    552.6982     6434.0939    6434.0939            90.0360   6391.5208           89.8200\n",
      "  223.4900    736.9309     9963.9757    9963.9757            90.0360   9902.7256           89.8200\n",
      "  223.4900    921.1636    14114.6655   14114.6655            90.0360  14032.7408           89.8200\n",
      "  223.4900   1105.3963    18886.1639   18886.1639            90.0360  18781.5648           89.8200\n",
      "  223.4900   1289.6290    24278.4745   24278.4745            90.0360  24149.2048           89.8200\n",
      "  223.4900   1473.8617    30291.5993   30291.5993            90.0360  30135.6544           89.8200\n",
      "  223.4900   1658.0945    36925.5137   36925.5137            90.0360  36740.9088           89.8200\n",
      "  223.4900   1842.3272    44180.2421   44180.2421            90.0360  43964.9696           89.8200\n",
      "  223.4900   2026.5599    52055.7738   52055.7738            90.0360  51807.8336           89.8200\n",
      "  223.4900   2210.7926    60552.1404   60552.1404            90.0360  60269.5424           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "  335.2350   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      "  335.2350   -184.2327        2.3874       2.3874            90.0100      2.3871           89.9500\n",
      "  335.2350     -0.0000        0.1994       0.1994             7.4540      0.2059            7.5200\n",
      "  335.2350    184.2327     1212.4131    1212.4131            90.0360   1201.3233           89.8200\n",
      "  335.2350    368.4654     3488.2801    3488.2801            90.0360   3462.5988           89.8200\n",
      "  335.2350    552.6982     6384.9564    6384.9564            90.0360   6342.6876           89.8200\n",
      "  335.2350    736.9309     9902.4427    9902.4427            90.0360   9841.5840           89.8200\n",
      "  335.2350    921.1636    14040.7377   14040.7377            90.0360  13959.2944           89.8200\n",
      "  335.2350   1105.3963    18799.8402   18799.8402            90.0360  18695.8192           89.8200\n",
      "  335.2350   1289.6290    24179.7571   24179.7571            90.0360  24051.1536           89.8200\n",
      "  335.2350   1473.8617    30180.4834   30180.4834            90.0360  30025.2992           89.8200\n",
      "  335.2350   1658.0945    36802.0050   36802.0050            90.0360  36618.2432           89.8200\n",
      "  335.2350   1842.3272    44044.3361   44044.3361            90.0360  43829.9968           89.8200\n",
      "  335.2350   2026.5599    51907.4712   51907.4712            90.0360  51660.5536           89.8200\n",
      "  335.2350   2210.7926    60391.4443   60391.4443            90.0360  60109.9776           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "  446.9800   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      "  446.9800   -184.2327        2.3874       2.3874            90.0100      2.3871           89.9500\n",
      "  446.9800     -0.0000        0.2008       0.2008             7.5360      0.2075            7.6200\n",
      "  446.9800    184.2327     1188.2608    1188.2608            90.0360   1177.2943           89.8200\n",
      "  446.9800    368.4654     3451.7322    3451.7322            90.0360   3426.2644           89.8200\n",
      "  446.9800    552.6982     6336.0131    6336.0131            90.0360   6294.0468           89.8200\n",
      "  446.9800    736.9309     9841.1038    9841.1038            90.0360   9780.6416           89.8200\n",
      "  446.9800    921.1636    13967.0032   13967.0032            90.0360  13886.0432           89.8200\n",
      "  446.9800   1105.3963    18713.7108   18713.7108            90.0360  18610.2544           89.8200\n",
      "  446.9800   1289.6290    24081.2315   24081.2315            90.0360  23953.2864           89.8200\n",
      "  446.9800   1473.8617    30069.5639   30069.5639            90.0360  29915.1328           89.8200\n",
      "  446.9800   1658.0945    36678.6871   36678.6871            90.0360  36495.7696           89.8200\n",
      "  446.9800   1842.3272    43908.6263   43908.6263            90.0360  43695.2192           89.8200\n",
      "  446.9800   2026.5599    51759.3640   51759.3640            90.0360  51513.4880           89.8200\n",
      "  446.9800   2210.7926    60230.9400   60230.9400            90.0360  59950.5728           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "  558.7250   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      "  558.7250   -184.2327        2.3874       2.3874            90.0100      2.3871           89.9500\n",
      "  558.7250     -0.0000        0.2032       0.2032             7.6420      0.2099            7.7400\n",
      "  558.7250    184.2327     1164.3027    1164.3027            90.0360   1153.4581           89.8200\n",
      "  558.7250    368.4654     3415.3780    3415.3780            90.0360   3390.1212           89.8200\n",
      "  558.7250    552.6982     6287.2636    6287.2636            90.0360   6245.5984           89.8200\n",
      "  558.7250    736.9309     9779.9590    9779.9590            90.0360   9719.8864           89.8200\n",
      "  558.7250    921.1636    13893.4631   13893.4631            90.0360  13812.9872           89.8200\n",
      "  558.7250   1105.3963    18627.7747   18627.7747            90.0360  18524.8928           89.8200\n",
      "  558.7250   1289.6290    23982.9005   23982.9005            90.0360  23855.6208           89.8200\n",
      "  558.7250   1473.8617    29958.8358   29958.8358            90.0360  29805.1520           89.8200\n",
      "  558.7250   1658.0945    36555.5671   36555.5671            90.0360  36373.4784           89.8200\n",
      "  558.7250   1842.3272    43773.1059   43773.1059            90.0360  43560.6304           89.8200\n",
      "  558.7250   2026.5599    51611.4497   51611.4497            90.0360  51366.5824           89.8200\n",
      "  558.7250   2210.7926    60070.6332   60070.6332            90.0360  59791.3856           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "  670.4700   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      "  670.4700   -184.2327        2.3874       2.3874            90.0080      2.3871           89.9500\n",
      "  670.4700     -0.0000        0.2071       0.2071             7.7780      0.2135            7.8500\n",
      "  670.4700    184.2327     1140.5385    1140.5385            90.0360   1129.8149           89.8200\n",
      "  670.4700    368.4654     3379.2178    3379.2178            90.0360   3354.1716           89.8200\n",
      "  670.4700    552.6982     6238.7078    6238.7078            90.0360   6197.3428           89.8200\n",
      "  670.4700    736.9309     9719.0076    9719.0076            90.0360   9659.3280           89.8200\n",
      "  670.4700    921.1636    13820.1158   13820.1158            90.0360  13740.1200           89.8200\n",
      "  670.4700   1105.3963    18542.0328   18542.0328            90.0360  18439.7216           89.8200\n",
      "  670.4700   1289.6290    23884.7628   23884.7628            90.0360  23758.1456           89.8200\n",
      "  670.4700   1473.8617    29848.3034   29848.3034            90.0360  29695.3728           89.8200\n",
      "  670.4700   1658.0945    36432.6370   36432.6370            90.0360  36251.3984           89.8200\n",
      "  670.4700   1842.3272    43637.7827   43637.7827            90.0360  43426.2432           89.8200\n",
      "  670.4700   2026.5599    51463.7317   51463.7317            90.0360  51219.8848           89.8200\n",
      "  670.4700   2210.7926    59910.5178   59910.5178            90.0360  59632.3840           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "  782.2150   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      "  782.2150   -184.2327        2.3874       2.3874            90.0080      2.3872           89.9400\n",
      "  782.2150     -0.0000        0.2132       0.2132             7.9780      0.2187            8.0100\n",
      "  782.2150    184.2327     1116.9682    1116.9682            90.0360   1106.3642           89.8200\n",
      "  782.2150    368.4654     3343.2513    3343.2513            90.0360   3318.4156           89.8200\n",
      "  782.2150    552.6982     6190.3459    6190.3459            90.0360   6149.2812           89.8200\n",
      "  782.2150    736.9309     9658.2501    9658.2501            90.0360   9598.9584           89.8200\n",
      "  782.2150    921.1636    13746.9633   13746.9633            90.0360  13667.4448           89.8200\n",
      "  782.2150   1105.3963    18456.4847   18456.4847            90.0360  18354.7456           89.8200\n",
      "  782.2150   1289.6290    23786.8180   23786.8180            90.0360  23660.8576           89.8200\n",
      "  782.2150   1473.8617    29737.9647   29737.9647            90.0360  29585.7824           89.8200\n",
      "  782.2150   1658.0945    36309.9016   36309.9016            90.0360  36129.5008           89.8200\n",
      "  782.2150   1842.3272    43502.6518   43502.6518            90.0360  43292.0416           89.8200\n",
      "  782.2150   2026.5599    51316.2064   51316.2064            90.0360  51073.3792           89.8300\n",
      "  782.2150   2210.7926    59750.5988   59750.5988            90.0380  59473.5808           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "  893.9600   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      "  893.9600   -184.2327        2.3875       2.3875            90.0000      2.3874           89.9500\n",
      "  893.9600     -0.0000        0.2220       0.2220             8.2600      0.2264            8.3300\n",
      "  893.9600    184.2327     1093.5919    1093.5919            90.0360   1083.1079           89.8200\n",
      "  893.9600    368.4654     3307.4787    3307.4787            90.0360   3282.8510           89.8200\n",
      "  893.9600    552.6982     6142.1778    6142.1778            90.0360   6101.4104           89.8200\n",
      "  893.9600    736.9309     9597.6870    9597.6870            90.0360   9538.7840           89.8200\n",
      "  893.9600    921.1636    13674.0039   13674.0039            90.0360  13594.9664           89.8200\n",
      "  893.9600   1105.3963    18371.1296   18371.1296            90.0360  18269.9584           89.8200\n",
      "  893.9600   1289.6290    23689.0683   23689.0683            90.0360  23563.7728           89.8200\n",
      "  893.9600   1473.8617    29627.8184   29627.8184            90.0360  29476.3872           89.8200\n",
      "  893.9600   1658.0945    36187.3610   36187.3610            90.0360  36007.7952           89.8200\n",
      "  893.9600   1842.3272    43367.7177   43367.7177            90.0360  43158.0384           89.8200\n",
      "  893.9600   2026.5599    51168.8743   51168.8743            90.0360  50927.0720           89.8300\n",
      "  893.9600   2210.7926    59590.8708   59590.8708            90.0380  59314.9568           89.8200\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      " 1005.7050   -368.4654        2.4433       2.4433            90.0000      2.4425           90.0000\n",
      " 1005.7050   -184.2327        2.3876       2.3876            89.9860      2.3880           89.9300\n",
      " 1005.7050     -0.0000        0.2344       0.2344             8.6540      0.2368            8.7100\n",
      " 1005.7050    184.2327     1070.4106    1070.4106            90.0360   1060.0459           89.8200\n",
      " 1005.7050    368.4654     3271.9000    3271.9000            90.0360   3247.4800           89.8200\n",
      " 1005.7050    552.6982     6094.2035    6094.2035            90.0360   6053.7344           89.8200\n",
      " 1005.7050    736.9309     9537.3169    9537.3169            90.0360   9478.8008           89.8200\n",
      " 1005.7050    921.1636    13601.2394   13601.2394            90.0360  13522.6752           89.8200\n",
      " 1005.7050   1105.3963    18285.9694   18285.9694            90.0360  18185.3632           89.8200\n",
      " 1005.7050   1289.6290    23591.5129   23591.5129            90.0360  23466.8704           89.8200\n",
      " 1005.7050   1473.8617    29517.8671   29517.8671            90.0360  29367.1776           89.8200\n",
      " 1005.7050   1658.0945    36065.0148   36065.0148            90.0360  35886.2912           89.8200\n",
      " 1005.7050   1842.3272    43232.9749   43232.9749            90.0360  43024.2112           89.8200\n",
      " 1005.7050   2026.5599    51021.7355   51021.7355            90.0360  50780.9312           89.8300\n",
      " 1005.7050   2210.7926    59431.3398   59431.3398            90.0360  59156.5568           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      " 1117.4500   -368.4654        2.4433       2.4433            90.0000      2.4426           90.0000\n",
      " 1117.4500   -184.2327        2.3879       2.3879            89.9860      2.3890           89.9300\n",
      " 1117.4500     -0.0000        0.2509       0.2509             9.1540      0.2509            9.4400\n",
      " 1117.4500    184.2327     1047.4271    1047.4271            90.0360   1037.1773           89.8200\n",
      " 1117.4500    368.4654     3236.5151    3236.5151            90.0360   3212.3004           89.8200\n",
      " 1117.4500    552.6982     6046.4231    6046.4231            90.0360   6006.2500           89.8200\n",
      " 1117.4500    736.9309     9477.1411    9477.1411            90.0360   9419.0112           89.8200\n",
      " 1117.4500    921.1636    13528.6680   13528.6680            90.0360  13450.5840           89.8200\n",
      " 1117.4500   1105.3963    18201.0023   18201.0023            90.0360  18100.9616           89.8200\n",
      " 1117.4500   1289.6290    23494.1505   23494.1505            90.0360  23370.1616           89.8200\n",
      " 1117.4500   1473.8617    29408.1091   29408.1091            90.0360  29258.1728           89.8200\n",
      " 1117.4500   1658.0945    35942.8607   35942.8607            90.0360  35764.9728           89.8200\n",
      " 1117.4500   1842.3272    43098.4271   43098.4271            90.0360  42890.5952           89.8200\n",
      " 1117.4500   2026.5599    50874.7938   50874.7938            90.0360  50635.0240           89.8300\n",
      " 1117.4500   2210.7926    59272.0027   59272.0027            90.0400  58998.3296           89.8300\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      " 1229.1950   -368.4654        2.4433       2.4433            90.0020      2.4427           90.0000\n",
      " 1229.1950   -184.2327        2.3886       2.3886            89.9840      2.3903           89.9100\n",
      " 1229.1950     -0.0000        0.2726       0.2726             9.8040      0.2698            9.9400\n",
      " 1229.1950    184.2327     1024.6434    1024.6434            90.0360   1014.5084           89.8200\n",
      " 1229.1950    368.4654     3201.3241    3201.3241            90.0360   3177.3140           89.8200\n",
      " 1229.1950    552.6982     5998.8365    5998.8365            90.0360   5958.9588           89.8200\n",
      " 1229.1950    736.9309     9417.1590    9417.1590            90.0360   9359.4136           89.8200\n",
      " 1229.1950    921.1636    13456.2903   13456.2903            90.0360  13378.6808           89.8200\n",
      " 1229.1950   1105.3963    18116.2305   18116.2305            90.0360  18016.7632           89.8200\n",
      " 1229.1950   1289.6290    23396.9820   23396.9820            90.0360  23273.6496           89.8200\n",
      " 1229.1950   1473.8617    29298.5455   29298.5455            90.0360  29149.3536           89.8200\n",
      " 1229.1950   1658.0945    35820.9019   35820.9019            90.0360  35643.8560           89.8200\n",
      " 1229.1950   1842.3272    42964.0697   42964.0697            90.0360  42757.1520           89.8200\n",
      " 1229.1950   2026.5599    50728.0425   50728.0425            90.0360  50489.2864           89.8300\n",
      " 1229.1950   2210.7926    59112.8659   59112.8659            90.0380  58840.3008           89.8400\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      " 1340.9400   -368.4654        2.4434       2.4434            90.0040      2.4431           90.0100\n",
      " 1340.9400   -184.2327        2.3901       2.3901            89.9720      2.3930           89.9100\n",
      " 1340.9400     -0.0000        0.3004       0.3004            10.5600      0.2954           10.7500\n",
      " 1340.9400    184.2327     1002.0618    1002.0618            90.0360    992.0418           89.8200\n",
      " 1340.9400    368.4654     3166.3270    3166.3270            90.0360   3142.5208           89.8200\n",
      " 1340.9400    552.6982     5951.4439    5951.4439            90.0360   5911.8588           89.8200\n",
      " 1340.9400    736.9309     9357.3709    9357.3709            90.0360   9300.0112           89.8200\n",
      " 1340.9400    921.1636    13384.1067   13384.1067            90.0360  13306.9712           89.8200\n",
      " 1340.9400   1105.3963    18031.6508   18031.6508            90.0360  17932.7392           89.8200\n",
      " 1340.9400   1289.6290    23300.0070   23300.0070            90.0360  23177.3232           89.8200\n",
      " 1340.9400   1473.8617    29189.1753   29189.1753            90.0360  29040.7232           89.8200\n",
      " 1340.9400   1658.0945    35699.1337   35699.1337            90.0360  35522.9184           89.8200\n",
      " 1340.9400   1842.3272    42829.9098   42829.9098            90.0360  42623.9328           89.8200\n",
      " 1340.9400   2026.5599    50581.4876   50581.4876            90.0360  50343.7504           89.8400\n",
      " 1340.9400   2210.7926    58953.9194   58953.9194            90.0380  58682.5088           89.8400\n"
     ]
    }
   ],
   "source": [
    "dxy_scale = 5\n",
    "base_model =  NN(input_dim=data_dim, \n",
    "                         hidden_dim=hidden_size, \n",
    "                         out_dim=out_dim, \n",
    "                         dropout_prob=dropout_prob).to(device)\n",
    "print(curve_coordinates)\n",
    "columns = ['X', 'Y', 'Train loss', 'Train nll', 'Train error (%)', 'Test nll', 'Test error (%)']\n",
    "\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    for j, beta in enumerate(betas):\n",
    "        p = np.array(origin + alpha * dxy_scale*dx * u + beta * dxy_scale*dy * v)\n",
    "        offset = 0\n",
    "        for parameter in base_model.parameters():\n",
    "            size = np.prod(parameter.size())\n",
    "            value = p[offset:offset+size].reshape(parameter.size())\n",
    "            parameter.data.copy_(torch.from_numpy(value)).to(device)\n",
    "            offset += size\n",
    "\n",
    "        # tr_res = utils.test(loaders['train'], base_model, criterion, regularizer)\n",
    "        # te_res = utils.test(loaders['test'], base_model, criterion, regularizer)\n",
    "        tr_res = eval(model=base_model, loader=train_loader)\n",
    "        te_res = eval(model=base_model, loader=valid_loader)\n",
    "\n",
    "\n",
    "        tr_loss_v, tr_nll_v, tr_acc_v = tr_res['loss'], tr_res['nll'], tr_res['accuracy']\n",
    "        te_loss_v, te_nll_v, te_acc_v = te_res['loss'], te_res['nll'], te_res['accuracy']\n",
    "\n",
    "        c = get_xy(p, origin, u, v)\n",
    "        grid[i, j] = [alpha * dxy_scale * dx, beta * dxy_scale * dy]\n",
    "\n",
    "        tr_loss[i, j] = tr_loss_v\n",
    "        tr_nll[i, j] = tr_nll_v\n",
    "        tr_acc[i, j] = tr_acc_v\n",
    "        tr_err[i, j] = 100.0 - tr_acc[i, j]\n",
    "\n",
    "        te_loss[i, j] = te_loss_v\n",
    "        te_nll[i, j] = te_nll_v\n",
    "        te_acc[i, j] = te_acc_v\n",
    "        te_err[i, j] = 100.0 - te_acc[i, j]\n",
    "\n",
    "        values = [\n",
    "            grid[i, j, 0], grid[i, j, 1], tr_loss[i, j], tr_nll[i, j], tr_err[i, j],\n",
    "            te_nll[i, j], te_err[i, j]\n",
    "        ]\n",
    "        table = tabulate.tabulate([values], columns, tablefmt='simple', floatfmt='10.4f')\n",
    "        if j == 0:\n",
    "            table = table.split('\\n')\n",
    "            table = '\\n'.join([table[1]] + table)\n",
    "        else:\n",
    "            table = table.split('\\n')[2]\n",
    "        print(table)\n",
    "\n",
    "np.savez(\n",
    "    os.path.join('./', f'plane_nonlinear_subspace_edges_random_dir_dxscale{dxy_scale}_dyscale{dxy_scale}_seed_{seed}_vanillaseed_{vanilla_seed}_beta_{train_beta}_activation_{activation}.npz'),\n",
    "    bend_coordinates=bend_coordinates,\n",
    "    curve_coordinates=curve_coordinates,\n",
    "    alphas=alphas,\n",
    "    betas=betas,\n",
    "    grid=grid,\n",
    "    tr_loss=tr_loss,\n",
    "    tr_acc=tr_acc,\n",
    "    tr_nll=tr_nll,\n",
    "    tr_err=tr_err,\n",
    "    te_loss=te_loss,\n",
    "    te_acc=te_acc,\n",
    "    te_nll=te_nll,\n",
    "    te_err=te_err\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
