{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import tabulate\n",
    "from sklearn.decomposition import PCA\n",
    "import os \n",
    "\n",
    "# os.chdir('/gpfs/commons/home/tchen/loss_sub_space_geometry_project/loss-subspace-geometry/src')\n",
    "os.chdir('/home/tristan/loss-subspace-geometry-project/loss-subspace-geometry/src')\n",
    "\n",
    "\n",
    "from models.mlp import SubspaceNN, NN, NonLinearSubspaceNN\n",
    "from models.subspace_layers import LinesNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/envs/loss-subspace/lib/python3.8/site-packages/torch/cuda/__init__.py:143: UserWarning: \n",
      "NVIDIA RTX A6000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA RTX A6000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp.linear.weight\n",
      "mlp.linear.bias\n",
      "mlp.linear.line.parameterization_linear_1.weight\n",
      "mlp.linear.line.parameterization_linear_1.bias\n",
      "mlp.linear.line.parameterization_linear_2.weight\n",
      "mlp.linear.line.parameterization_linear_2.bias\n",
      "out.weight\n",
      "out.bias\n",
      "out.line.parameterization_linear_1.weight\n",
      "out.line.parameterization_linear_1.bias\n",
      "out.line.parameterization_linear_2.weight\n",
      "out.line.parameterization_linear_2.bias\n",
      "\n",
      "mlp.linear.weight\n",
      "mlp.linear.bias\n",
      "mlp.linear.line.parameterization_linear_1.weight\n",
      "mlp.linear.line.parameterization_linear_1.bias\n",
      "mlp.linear.line.parameterization_linear_2.weight\n",
      "mlp.linear.line.parameterization_linear_2.bias\n",
      "out.weight\n",
      "out.bias\n",
      "out.line.parameterization_linear_1.weight\n",
      "out.line.parameterization_linear_1.bias\n",
      "out.line.parameterization_linear_2.weight\n",
      "out.line.parameterization_linear_2.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configs\n",
    "data_dim = 784\n",
    "hidden_size = 512\n",
    "out_dim = 10\n",
    "dropout_prob = 0.3\n",
    "seed = 11202022\n",
    "# device = torch.device('cuda')\n",
    "device = torch.device('cuda:2')\n",
    "\n",
    "# model_path = '/gpfs/commons/home/tchen/loss_sub_space_geometry_project/loss-subspace-geometry-save/models/subspace_vanilla_mlp_0.pt'\n",
    "model_path = '/home/tristan/loss-subspace-geometry-project/loss-subspace-geometry-save/models/nonlinear_subspace_vanilla_mlp_0.pt'\n",
    "\n",
    "curve_model = NonLinearSubspaceNN(input_dim=data_dim, \n",
    "                         hidden_dim=hidden_size, \n",
    "                         out_dim=out_dim, \n",
    "                         dropout_prob=dropout_prob, \n",
    "                         seed=seed).to(device)\n",
    "\n",
    "for tuple in curve_model.state_dict():\n",
    "    print(tuple)\n",
    "print()\n",
    "checkpoint = torch.load(model_path)\n",
    "for tuple in checkpoint:\n",
    "    print(tuple)\n",
    "curve_model.load_state_dict(checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more configs\n",
    "curve_points = 61\n",
    "grid_points = 21\n",
    "margin_left = 0.2\n",
    "margin_right = 0.2\n",
    "margin_bottom = 0.2\n",
    "margin_top = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NonLinearSubspaceNN(\n",
       "  (mlp): NonLinearSubspaceMLP(\n",
       "    (linear): LinesNN(\n",
       "      in_features=784, out_features=512, bias=True\n",
       "      (line): ParameterizedSubspace(\n",
       "        (parameterization_linear_1): Linear(in_features=1, out_features=10, bias=True)\n",
       "        (parameterization_linear_2): Linear(in_features=10, out_features=401408, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (out): LinesNN(\n",
       "    in_features=512, out_features=10, bias=True\n",
       "    (line): ParameterizedSubspace(\n",
       "      (parameterization_linear_1): Linear(in_features=1, out_features=10, bias=True)\n",
       "      (parameterization_linear_2): Linear(in_features=10, out_features=5120, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_parameters = list(curve_model.parameters())\n",
    "w = []\n",
    "\n",
    "# actual neural net\n",
    "w.append(np.concatenate([\n",
    "        # weights layer 1, biases layer 1, weights layer 2, biases layer 2\n",
    "        p.data.cpu().numpy().ravel() for p in [curve_parameters[0], curve_parameters[1], curve_parameters[6], curve_parameters[7]]\n",
    "    ]))\n",
    "\n",
    "# subspace network 1 parameters\n",
    "w.append(np.concatenate([\n",
    "        # weights layer 1, biases layer 1, weights layer 2, biases layer 2\n",
    "        p.data.cpu().numpy().ravel() for p in [curve_parameters[2], curve_parameters[3], curve_parameters[4], curve_parameters[5]]\n",
    "    ]))\n",
    "\n",
    "# subspace network 2 parameters\n",
    "w.append(np.concatenate([\n",
    "        # weights layer 1, biases layer 1, weights layer 2, biases layer 2\n",
    "        p.data.cpu().numpy().ravel() for p in [curve_parameters[8], curve_parameters[9], curve_parameters[10], curve_parameters[11]]\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isolated_model = NN(input_dim=data_dim, \n",
    "                         hidden_dim=hidden_size, \n",
    "                         out_dim=out_dim, \n",
    "                         dropout_prob=dropout_prob).to(device)\n",
    "# isolated_checkpoint = torch.load('/gpfs/commons/home/tchen/loss_sub_space_geometry_project/loss-subspace-geometry-save/models/vanilla_mlp.pt')\n",
    "isolated_checkpoint = torch.load('/home/tristan/loss-subspace-geometry-project/loss-subspace-geometry-save/models/vanilla_mlp_0.pt')\n",
    "isolated_model.load_state_dict(isolated_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (mlp): MLP(\n",
       "    (linear): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (out): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isolated_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w.append(np.concatenate([\n",
    "#         p.data.cpu().numpy().ravel() for p in list(isolated_model.parameters())\n",
    "#     ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_subspace(alpha, subspace_net_1, subspace_net_2):\n",
    "    alpha = torch.tensor([float(alpha)])\n",
    "    setattr(subspace_net_1, 'alpha', alpha)\n",
    "    setattr(subspace_net_2, 'alpha', alpha)\n",
    "    w1 = subspace_net_1.get_weight().clone().detach()\n",
    "    b1 = curve_parameters[1].clone().detach().cpu()\n",
    "    w2 = subspace_net_2.get_weight().clone().detach()\n",
    "    b2 = curve_parameters[7].clone().detach().cpu()\n",
    "    weights = torch.cat([w1,b1,w2,b2]).numpy()\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample uniformly from subspace ##\n",
    "samples = 100\n",
    "alphas = np.random.uniform(low=0, high=1, size=(samples))\n",
    "\n",
    "# instantiate both subspace networks\n",
    "subspace_net_1 = LinesNN(\n",
    "    in_features=data_dim,\n",
    "    out_features=hidden_size\n",
    ")\n",
    "\n",
    "subspace_net_2 = LinesNN(\n",
    "    in_features=hidden_size,\n",
    "    out_features=out_dim\n",
    ")\n",
    "\n",
    "# fetch weights from trained subspace networks\n",
    "subspace_net_1_weights = [curve_parameters[2], curve_parameters[3], curve_parameters[4], curve_parameters[5]]\n",
    "subspace_net_2_weights = [curve_parameters[8], curve_parameters[9], curve_parameters[10], curve_parameters[11]]\n",
    "\n",
    "# set subspace network weights\n",
    "with torch.no_grad():\n",
    "    subspace_net_1.line.parameterization_linear_1.weight.copy_(curve_parameters[2])\n",
    "    subspace_net_1.line.parameterization_linear_1.bias.copy_(curve_parameters[3])\n",
    "    subspace_net_1.line.parameterization_linear_2.weight.copy_(curve_parameters[4])\n",
    "    subspace_net_1.line.parameterization_linear_2.bias.copy_(curve_parameters[5])\n",
    "\n",
    "    subspace_net_2.line.parameterization_linear_1.weight.copy_(curve_parameters[8])\n",
    "    subspace_net_2.line.parameterization_linear_1.bias.copy_(curve_parameters[9])\n",
    "    subspace_net_2.line.parameterization_linear_2.weight.copy_(curve_parameters[10])\n",
    "    subspace_net_2.line.parameterization_linear_2.bias.copy_(curve_parameters[11])\n",
    "\n",
    "# sample points in weight space\n",
    "weight_space_points = []\n",
    "for alpha in alphas:\n",
    "    weights = sample_subspace(alpha, subspace_net_1, subspace_net_2)\n",
    "    weight_space_points.append(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 407050)\n"
     ]
    }
   ],
   "source": [
    "# Perform PCA on sampled weight space points to get top two principle eigenvectors\n",
    "weight_space_points = np.asarray(weight_space_points)\n",
    "pca = PCA().fit(weight_space_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight space dimensionality: 407050\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set up for grid for plane plotting\n",
    "\n",
    "def get_xy(point, origin, vector_x, vector_y):\n",
    "    return np.array([np.dot(point - origin, vector_x), np.dot(point - origin, vector_y)])\n",
    "\n",
    "\n",
    "print('Weight space dimensionality: %d' % w[0].shape[0])\n",
    "\n",
    "u = pca.components_[1]\n",
    "dx = np.linalg.norm(u)\n",
    "u /= dx\n",
    "\n",
    "v = pca.components_[-5]\n",
    "v -= np.dot(u, v) * u\n",
    "dy = np.linalg.norm(v)\n",
    "v /= dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate corners of hyperplane via projection onto principal vecs\n",
    "origin = sample_subspace(0.0, subspace_net_1, subspace_net_2)\n",
    "c3 = sample_subspace(1.0, subspace_net_1, subspace_net_2)\n",
    "c2 = origin + np.dot(u, c3)*u\n",
    "# c4 = origin + np.dot(v, c3)*v\n",
    "\n",
    "# w_corners = [origin, c2, c3, c4]\n",
    "w_corners = [origin, c2, c3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  0.0000000e+00]\n",
      " [ 3.2570023e+01 -8.4167242e-09]\n",
      " [ 1.4411945e+00  1.5231785e-03]]\n"
     ]
    }
   ],
   "source": [
    "bend_coordinates = np.stack(get_xy(p, origin, u, v) for p in w_corners)\n",
    "print(bend_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model: nn.Module, t):\n",
    "    weights = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear) and 'parameterization' not in name:\n",
    "            # add attribute for weight dimensionality and subspace dimensionality\n",
    "            setattr(module, f'alpha', torch.tensor([t], dtype=torch.float32, device=device))\n",
    "            print(module.get_weight())\n",
    "            weights.extend([module.get_weight(), module.bias.data])\n",
    "        # weights.extend([w for w in module.compute_weights_t(coeffs_t) if w is not None])\n",
    "    return np.concatenate([w.detach().cpu().numpy().ravel() for w in weights])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0.0, 1.0, curve_points)\n",
    "curve_coordinates = []\n",
    "for t in np.linspace(0.0, 1.0, curve_points):\n",
    "    weights = sample_subspace(t, subspace_net_1, subspace_net_2)\n",
    "    curve_coordinates.append(get_xy(weights, origin, u, v))\n",
    "\n",
    "curve_coordinates = np.stack(curve_coordinates)\n",
    "\n",
    "G = grid_points\n",
    "alphas = np.linspace(0.0 - margin_left, 1.0 + margin_right, G)\n",
    "betas = np.linspace(0.0 - margin_bottom, 1.0 + margin_top, G)\n",
    "\n",
    "tr_loss = np.zeros((G, G))\n",
    "tr_nll = np.zeros((G, G))\n",
    "tr_acc = np.zeros((G, G))\n",
    "tr_err = np.zeros((G, G))\n",
    "\n",
    "te_loss = np.zeros((G, G))\n",
    "te_nll = np.zeros((G, G))\n",
    "te_acc = np.zeros((G, G))\n",
    "te_err = np.zeros((G, G))\n",
    "\n",
    "grid = np.zeros((G, G, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even more configs for evaluating on FashionMNIST\n",
    "\n",
    "# data_dir = '/gpfs/commons/home/tchen/loss_sub_space_geometry_project/data/'\n",
    "data_dir = '/home/tristan/loss-subspace-geometry-project/data/'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "FashionMNIST_data_train = torchvision.datasets.FashionMNIST(\n",
    "    data_dir, train=True, transform=transform, download=False)\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(\n",
    "    FashionMNIST_data_train, [50000, 10000])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    val_set, batch_size=len(val_set), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model: nn.Module, loader):\n",
    "    running_loss = 0.0\n",
    "    num_right = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "            reshaped_x = x.reshape(x.size(0), 784)\n",
    "            y_hat = model(reshaped_x.to(device))\n",
    "            num_right += torch.sum(\n",
    "                y.to(device) == torch.argmax(\n",
    "                    y_hat, dim=-1)).detach().cpu().item()\n",
    "\n",
    "            running_loss += criterion(y_hat, y.to(device)).item()\n",
    "    return {\n",
    "        'nll': running_loss / len(loader.dataset),\n",
    "        'loss': running_loss / len(loader.dataset),\n",
    "        'accuracy': num_right * 100.0 / len(loader.dataset),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (mlp): MLP(\n",
      "    (linear): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (out): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "   -0.2000     -0.2000        0.4590       0.4590            15.5100      0.4694           16.1700\n",
      "   -0.2000     -0.1300        0.4536       0.4536            15.2180      0.4642           15.9500\n",
      "   -0.2000     -0.0600        0.4510       0.4510            15.1320      0.4618           15.8500\n",
      "   -0.2000      0.0100        0.4514       0.4514            15.1840      0.4624           15.8400\n",
      "   -0.2000      0.0800        0.4551       0.4551            15.4100      0.4663           15.9700\n",
      "   -0.2000      0.1500        0.4618       0.4618            15.7360      0.4732           16.3900\n",
      "   -0.2000      0.2200        0.4711       0.4711            16.1760      0.4827           16.7700\n",
      "   -0.2000      0.2900        0.4834       0.4834            16.7900      0.4950           17.2400\n",
      "   -0.2000      0.3600        0.4988       0.4988            17.5360      0.5104           17.8600\n",
      "   -0.2000      0.4300        0.5176       0.5176            18.4080      0.5290           18.6800\n",
      "   -0.2000      0.5000        0.5397       0.5397            19.2900      0.5509           19.3600\n",
      "   -0.2000      0.5700        0.5654       0.5654            20.1240      0.5761           20.1400\n",
      "   -0.2000      0.6400        0.5947       0.5947            20.8700      0.6050           21.0000\n",
      "   -0.2000      0.7100        0.6280       0.6280            21.7020      0.6375           21.7100\n",
      "   -0.2000      0.7800        0.6653       0.6653            22.5220      0.6738           22.4800\n",
      "   -0.2000      0.8500        0.7068       0.7068            23.3600      0.7140           23.1300\n",
      "   -0.2000      0.9200        0.7528       0.7528            24.3040      0.7586           23.8800\n",
      "   -0.2000      0.9900        0.8035       0.8035            25.1700      0.8076           24.7700\n",
      "   -0.2000      1.0600        0.8594       0.8594            26.0880      0.8617           25.6400\n",
      "   -0.2000      1.1300        0.9207       0.9207            27.0940      0.9210           26.8100\n",
      "   -0.2000      1.2000        0.9878       0.9878            28.2440      0.9860           27.8700\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "   -0.1300     -0.2000        0.4503       0.4503            15.3080      0.4601           15.8200\n",
      "   -0.1300     -0.1300        0.4445       0.4445            15.0920      0.4547           15.4600\n",
      "   -0.1300     -0.0600        0.4413       0.4413            14.9240      0.4518           15.4800\n",
      "   -0.1300      0.0100        0.4409       0.4409            14.9020      0.4517           15.3300\n",
      "   -0.1300      0.0800        0.4437       0.4437            15.0320      0.4547           15.5300\n",
      "   -0.1300      0.1500        0.4493       0.4493            15.2940      0.4608           15.7000\n",
      "   -0.1300      0.2200        0.4574       0.4574            15.6280      0.4693           16.1400\n",
      "   -0.1300      0.2900        0.4684       0.4684            16.1380      0.4804           16.5900\n",
      "   -0.1300      0.3600        0.4823       0.4823            16.7600      0.4945           17.1400\n",
      "   -0.1300      0.4300        0.4993       0.4993            17.4940      0.5117           17.6800\n",
      "   -0.1300      0.5000        0.5198       0.5198            18.3360      0.5322           18.5900\n",
      "   -0.1300      0.5700        0.5438       0.5438            19.2240      0.5561           19.4300\n",
      "   -0.1300      0.6400        0.5716       0.5716            20.1380      0.5836           20.4100\n",
      "   -0.1300      0.7100        0.6034       0.6034            21.0300      0.6149           21.2500\n",
      "   -0.1300      0.7800        0.6394       0.6394            21.9020      0.6503           22.2100\n",
      "   -0.1300      0.8500        0.6799       0.6799            22.9680      0.6898           22.8600\n",
      "   -0.1300      0.9200        0.7252       0.7252            24.0420      0.7340           23.8200\n",
      "   -0.1300      0.9900        0.7757       0.7757            24.9620      0.7830           24.6200\n",
      "   -0.1300      1.0600        0.8317       0.8317            26.0100      0.8374           25.6500\n",
      "   -0.1300      1.1300        0.8937       0.8937            27.1360      0.8974           26.7900\n",
      "   -0.1300      1.2000        0.9620       0.9620            28.3560      0.9637           27.8900\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "   -0.0600     -0.2000        0.4462       0.4462            15.2920      0.4553           15.7600\n",
      "   -0.0600     -0.1300        0.4400       0.4400            15.0000      0.4495           15.4800\n",
      "   -0.0600     -0.0600        0.4363       0.4363            14.8500      0.4461           15.2800\n",
      "   -0.0600      0.0100        0.4351       0.4351            14.7180      0.4453           15.1300\n",
      "   -0.0600      0.0800        0.4368       0.4368            14.7680      0.4475           15.1500\n",
      "   -0.0600      0.1500        0.4414       0.4414            14.9540      0.4526           15.2600\n",
      "   -0.0600      0.2200        0.4485       0.4485            15.2380      0.4602           15.4300\n",
      "   -0.0600      0.2900        0.4582       0.4582            15.6740      0.4704           15.9500\n",
      "   -0.0600      0.3600        0.4707       0.4707            16.1480      0.4832           16.5000\n",
      "   -0.0600      0.4300        0.4862       0.4862            16.7740      0.4991           16.8700\n",
      "   -0.0600      0.5000        0.5050       0.5050            17.5020      0.5182           17.5600\n",
      "   -0.0600      0.5700        0.5274       0.5274            18.3620      0.5406           18.7100\n",
      "   -0.0600      0.6400        0.5534       0.5534            19.3060      0.5667           19.5300\n",
      "   -0.0600      0.7100        0.5836       0.5836            20.3320      0.5967           20.6800\n",
      "   -0.0600      0.7800        0.6182       0.6182            21.3940      0.6309           21.5700\n",
      "   -0.0600      0.8500        0.6574       0.6574            22.5180      0.6695           22.5200\n",
      "   -0.0600      0.9200        0.7019       0.7019            23.5920      0.7130           23.4400\n",
      "   -0.0600      0.9900        0.7518       0.7518            24.7480      0.7618           24.4500\n",
      "   -0.0600      1.0600        0.8079       0.8079            25.8960      0.8163           25.5500\n",
      "   -0.0600      1.1300        0.8704       0.8704            27.1220      0.8772           26.7100\n",
      "   -0.0600      1.2000        0.9400       0.9400            28.3600      0.9448           27.9400\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "    0.0100     -0.2000        0.4469       0.4469            15.3120      0.4551           15.7100\n",
      "    0.0100     -0.1300        0.4403       0.4403            15.0520      0.4489           15.4300\n",
      "    0.0100     -0.0600        0.4359       0.4359            14.8680      0.4449           15.2300\n",
      "    0.0100      0.0100        0.4340       0.4340            14.7660      0.4435           15.0700\n",
      "    0.0100      0.0800        0.4347       0.4347            14.7520      0.4448           15.0600\n",
      "    0.0100      0.1500        0.4383       0.4383            14.9260      0.4491           15.0800\n",
      "    0.0100      0.2200        0.4444       0.4444            15.1040      0.4558           15.4200\n",
      "    0.0100      0.2900        0.4530       0.4530            15.4540      0.4650           15.7200\n",
      "    0.0100      0.3600        0.4643       0.4643            15.8360      0.4768           16.0700\n",
      "    0.0100      0.4300        0.4784       0.4784            16.2900      0.4915           16.6800\n",
      "    0.0100      0.5000        0.4957       0.4957            16.8480      0.5092           17.2200\n",
      "    0.0100      0.5700        0.5164       0.5164            17.6380      0.5302           17.9300\n",
      "    0.0100      0.6400        0.5408       0.5408            18.5560      0.5548           18.8300\n",
      "    0.0100      0.7100        0.5693       0.5693            19.5280      0.5834           19.7800\n",
      "    0.0100      0.7800        0.6023       0.6023            20.6060      0.6162           20.6300\n",
      "    0.0100      0.8500        0.6403       0.6403            21.8180      0.6538           21.8100\n",
      "    0.0100      0.9200        0.6836       0.6836            23.0880      0.6964           22.9900\n",
      "    0.0100      0.9900        0.7329       0.7329            24.3120      0.7447           24.2400\n",
      "    0.0100      1.0600        0.7887       0.7887            25.5700      0.7993           25.4600\n",
      "    0.0100      1.1300        0.8516       0.8516            27.0040      0.8608           26.7200\n",
      "    0.0100      1.2000        0.9224       0.9224            28.4520      0.9298           28.0000\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "    0.0800     -0.2000        0.4527       0.4527            15.5120      0.4598           15.9300\n",
      "    0.0800     -0.1300        0.4456       0.4456            15.2460      0.4531           15.5500\n",
      "    0.0800     -0.0600        0.4406       0.4406            15.0740      0.4487           15.4100\n",
      "    0.0800      0.0100        0.4379       0.4379            14.9820      0.4466           15.2700\n",
      "    0.0800      0.0800        0.4377       0.4377            14.9160      0.4470           15.0900\n",
      "    0.0800      0.1500        0.4403       0.4403            14.9860      0.4504           15.0700\n",
      "    0.0800      0.2200        0.4455       0.4455            15.1340      0.4563           15.4000\n",
      "    0.0800      0.2900        0.4531       0.4531            15.3700      0.4646           15.7200\n",
      "    0.0800      0.3600        0.4633       0.4633            15.7040      0.4755           15.8900\n",
      "    0.0800      0.4300        0.4762       0.4762            16.0980      0.4890           16.3600\n",
      "    0.0800      0.5000        0.4920       0.4920            16.6080      0.5055           16.9300\n",
      "    0.0800      0.5700        0.5112       0.5112            17.1960      0.5251           17.7200\n",
      "    0.0800      0.6400        0.5340       0.5340            17.9680      0.5483           18.3400\n",
      "    0.0800      0.7100        0.5608       0.5608            18.8380      0.5755           19.0300\n",
      "    0.0800      0.7800        0.5922       0.5922            19.9200      0.6069           20.0500\n",
      "    0.0800      0.8500        0.6287       0.6287            21.0420      0.6433           21.0700\n",
      "    0.0800      0.9200        0.6708       0.6708            22.3720      0.6850           22.2200\n",
      "    0.0800      0.9900        0.7192       0.7192            23.7340      0.7328           23.5600\n",
      "    0.0800      1.0600        0.7748       0.7748            25.1080      0.7873           24.8900\n",
      "    0.0800      1.1300        0.8380       0.8380            26.6620      0.8494           26.5100\n",
      "    0.0800      1.2000        0.9099       0.9099            28.1240      0.9199           27.9400\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "    0.1500     -0.2000        0.4641       0.4641            15.9020      0.4698           16.3300\n",
      "    0.1500     -0.1300        0.4565       0.4565            15.6460      0.4627           15.9300\n",
      "    0.1500     -0.0600        0.4509       0.4509            15.4200      0.4577           15.7200\n",
      "    0.1500      0.0100        0.4475       0.4475            15.2920      0.4550           15.5000\n",
      "    0.1500      0.0800        0.4464       0.4464            15.2440      0.4546           15.4900\n",
      "    0.1500      0.1500        0.4480       0.4480            15.2760      0.4571           15.2900\n",
      "    0.1500      0.2200        0.4523       0.4523            15.3600      0.4622           15.5000\n",
      "    0.1500      0.2900        0.4591       0.4591            15.5840      0.4698           15.6300\n",
      "    0.1500      0.3600        0.4683       0.4683            15.8020      0.4798           15.9700\n",
      "    0.1500      0.4300        0.4801       0.4801            16.1060      0.4924           16.4400\n",
      "    0.1500      0.5000        0.4947       0.4947            16.5520      0.5077           16.8500\n",
      "    0.1500      0.5700        0.5124       0.5124            17.0740      0.5262           17.3900\n",
      "    0.1500      0.6400        0.5337       0.5337            17.7180      0.5481           18.0500\n",
      "    0.1500      0.7100        0.5590       0.5590            18.4280      0.5738           18.7700\n",
      "    0.1500      0.7800        0.5888       0.5888            19.3440      0.6040           19.4600\n",
      "    0.1500      0.8500        0.6239       0.6239            20.4740      0.6391           20.4500\n",
      "    0.1500      0.9200        0.6648       0.6648            21.7500      0.6798           21.6000\n",
      "    0.1500      0.9900        0.7124       0.7124            23.0780      0.7270           22.6100\n",
      "    0.1500      1.0600        0.7675       0.7675            24.5080      0.7815           24.1500\n",
      "    0.1500      1.1300        0.8311       0.8311            26.1240      0.8443           25.8300\n",
      "    0.1500      1.2000        0.9041       0.9041            27.7020      0.9164           27.7400\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "         X           Y    Train loss    Train nll    Train error (%)    Test nll    Test error (%)\n",
      "----------  ----------  ------------  -----------  -----------------  ----------  ----------------\n",
      "    0.2200     -0.2000        0.4817       0.4817            16.3640      0.4859           16.7700\n",
      "    0.2200     -0.1300        0.4737       0.4737            16.1560      0.4784           16.4800\n",
      "    0.2200     -0.0600        0.4675       0.4675            15.9120      0.4729           16.3600\n",
      "    0.2200      0.0100        0.4634       0.4634            15.8160      0.4695           16.1000\n",
      "    0.2200      0.0800        0.4615       0.4615            15.7840      0.4683           16.0500\n",
      "    0.2200      0.1500        0.4622       0.4622            15.7880      0.4700           16.0900\n",
      "    0.2200      0.2200        0.4657       0.4657            15.8760      0.4744           16.1000\n",
      "    0.2200      0.2900        0.4718       0.4718            16.0360      0.4813           16.1100\n",
      "    0.2200      0.3600        0.4802       0.4802            16.2120      0.4906           16.3200\n"
     ]
    }
   ],
   "source": [
    "dxy_scale = 50\n",
    "base_model =  NN(input_dim=data_dim, \n",
    "                         hidden_dim=hidden_size, \n",
    "                         out_dim=out_dim, \n",
    "                         dropout_prob=dropout_prob).to(device)\n",
    "print(base_model)\n",
    "columns = ['X', 'Y', 'Train loss', 'Train nll', 'Train error (%)', 'Test nll', 'Test error (%)']\n",
    "\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    for j, beta in enumerate(betas):\n",
    "        p = np.array(origin + alpha * dxy_scale*dx * u + beta * dxy_scale*dy * v)\n",
    "        offset = 0\n",
    "        for parameter in base_model.parameters():\n",
    "            size = np.prod(parameter.size())\n",
    "            value = p[offset:offset+size].reshape(parameter.size())\n",
    "            parameter.data.copy_(torch.from_numpy(value)).to(device)\n",
    "            offset += size\n",
    "\n",
    "        # tr_res = utils.test(loaders['train'], base_model, criterion, regularizer)\n",
    "        # te_res = utils.test(loaders['test'], base_model, criterion, regularizer)\n",
    "        tr_res = eval(model=base_model, loader=train_loader)\n",
    "        te_res = eval(model=base_model, loader=valid_loader)\n",
    "\n",
    "\n",
    "        tr_loss_v, tr_nll_v, tr_acc_v = tr_res['loss'], tr_res['nll'], tr_res['accuracy']\n",
    "        te_loss_v, te_nll_v, te_acc_v = te_res['loss'], te_res['nll'], te_res['accuracy']\n",
    "\n",
    "        c = get_xy(p, origin, u, v)\n",
    "        grid[i, j] = [alpha * dx, beta * dy]\n",
    "\n",
    "        tr_loss[i, j] = tr_loss_v\n",
    "        tr_nll[i, j] = tr_nll_v\n",
    "        tr_acc[i, j] = tr_acc_v\n",
    "        tr_err[i, j] = 100.0 - tr_acc[i, j]\n",
    "\n",
    "        te_loss[i, j] = te_loss_v\n",
    "        te_nll[i, j] = te_nll_v\n",
    "        te_acc[i, j] = te_acc_v\n",
    "        te_err[i, j] = 100.0 - te_acc[i, j]\n",
    "\n",
    "        values = [\n",
    "            grid[i, j, 0], grid[i, j, 1], tr_loss[i, j], tr_nll[i, j], tr_err[i, j],\n",
    "            te_nll[i, j], te_err[i, j]\n",
    "        ]\n",
    "        table = tabulate.tabulate([values], columns, tablefmt='simple', floatfmt='10.4f')\n",
    "        if j == 0:\n",
    "            table = table.split('\\n')\n",
    "            table = '\\n'.join([table[1]] + table)\n",
    "        else:\n",
    "            table = table.split('\\n')[2]\n",
    "        print(table)\n",
    "\n",
    "np.savez(\n",
    "    os.path.join('./', 'plane_nonlinear_top1_evector_bottom5_evector_dxyscale10.npz'),\n",
    "    ts=ts,\n",
    "    bend_coordinates=bend_coordinates,\n",
    "    curve_coordinates=curve_coordinates,\n",
    "    alphas=alphas,\n",
    "    betas=betas,\n",
    "    grid=grid,\n",
    "    tr_loss=tr_loss,\n",
    "    tr_acc=tr_acc,\n",
    "    tr_nll=tr_nll,\n",
    "    tr_err=tr_err,\n",
    "    te_loss=te_loss,\n",
    "    te_acc=te_acc,\n",
    "    te_nll=te_nll,\n",
    "    te_err=te_err\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
